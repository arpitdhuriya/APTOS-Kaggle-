{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for the balace of classes\nclas=[0,0,0,0,0]\nfor p in df['diagnosis']:\n  clas[p] = clas[p]+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(clas,'ro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clahe_greyscale(input_path):\n    img = cv2.imread(input_path)\n    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    cl1 = clahe.apply(gray_image)   \n    #cl1=cv2.resize(cl1,(512,512))\n    return cl1\ndef equalize_hist(input_path):\n    img = cv2.imread(input_path)\n    for c in range(0, 2):\n        img[:,:,c] = cv2.equalizeHist(img[:,:,c])\n    #img=cv2.resize(img,(512,512))\n    return img\n\ndef clahe_rgb(bgr):\n    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n    lab_planes = cv2.split(lab)\n    gridsize = 5\n    clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(gridsize,gridsize))\n    lab_planes[0] = clahe.apply(lab_planes[0])\n    lab = cv2.merge(lab_planes)\n    bgr2 = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n    #bgr2=cv2.resize(bgr2,(512,512))\n    return bgr2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler \nimport numpy as np\nros =RandomOverSampler(random_state=0)\nX1=df['id_code']\nX1=np.array(X1).reshape(-1,1)\nY1=df['diagnosis']\nX_r,Y_r=ros.fit_resample(X1,Y1)\nfrom collections import Counter\nprint(sorted(Counter(Y_r).items()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scaleRadius(img,scale):\n  x=img[img.shape[0]//2,:,:].sum(1)\n  r=(x>x.mean()/10).sum()/2\n  s=scale*1.0/r\n  return cv2.resize(img,(0,0),fx=s,fy=s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfs = pd.concat([pd.DataFrame(X_r),pd.DataFrame(Y_r)],axis=1)\ndfs.columns=['id_code','diagnosis']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfs[dfs['id_code']=='0024cdab0c1e']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preP(path):\n  img = cv2.imread(path)\n  \n  hsv1=cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n  h,s,v=cv2.split(hsv1)\n  hsv1=cv2.merge((h,s,v))\n  img2=cv2.cvtColor(hsv1,cv2.COLOR_HSV2RGB)\n\n  img_yuv = cv2.cvtColor(img2, cv2.COLOR_BGR2YUV)\n\n  img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n\n\n  img2 = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n  img2 = cv2.GaussianBlur(img2,(5,5),cv2.BORDER_DEFAULT)\n  \n\n  return img2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport skimage as sk\nimport random\nfrom tqdm import tqdm\nimport os\nimport cv2\nfrom scipy.ndimage import rotate\nfrom skimage.io import imshow, show\n\ndef crop_image(img,tol=7):\n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\nj=0\nfrom tensorflow.keras.preprocessing.image import img_to_array\ntr = []\ni=0\nfor i,image in enumerate(tqdm(os.listdir('../input/aptos2019-blindness-detection/train_images'))):\n    x=dfs[dfs['id_code']==image.split('.')[0]].values\n    for row in x:\n      scale = 300\n      img = preP('../input/aptos2019-blindness-detection/train_images/'+image)\n      img = scaleRadius(img,scale)\n      \n      h,w,_ = img.shape\n      img1=cv2.resize(crop_image(img[:,:,0]),(w,h))\n      img2=cv2.resize(crop_image(img[:,:,1]),(w,h))\n      img3=cv2.resize(crop_image(img[:,:,2]),(w,h))\n      img[:,:,0]=img1\n      img[:,:,1]=img2\n      img[:,:,2]=img3\n      imgr = cv2.resize(img,(224,224))\n      Y= row[1]\n      tr.append([imgr,Y])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\ntr =shuffle(tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=[]\nY=[]\nfor image,label in tr:\n    X.append(image)\n    Y.append(label)\nX=np.array(X).reshape(-1,224,224,3)\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = pd.get_dummies(Y).values\nY_t = np.empty(Y.shape, dtype=Y.dtype)\nY_t[:, 4] = Y[:, 4]\n\nfor i in range(3, -1, -1):\n    Y_t[:, i] = np.logical_or(Y[:, i], Y_t[:, i+1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(\n    X,Y_t, \n    test_size=0.15, \n    random_state=1009\n)\nX=[]\nY=[]\nY_t=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nBATCH_SIZE = 32\ndef create_datagen():\n    return ImageDataGenerator(\n        zoom_range=0.15,  \n        fill_mode='constant',\n        cval=0.,  \n        horizontal_flip=True,  \n        vertical_flip=True,  \n    )\n  \ndata_generator = create_datagen().flow(x_train, y_train, batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import DenseNet121\ndensenet = DenseNet121(\n    weights='../input/petfinder-external/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    input_shape=(224,224,3)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import layers\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport numpy as np\nimport tensorflow as tf\nfrom keras.optimizers import Adam\n\n\nmodel = Sequential()\nmodel.add(densenet)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(5, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.00005),metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(\n    data_generator,\n    steps_per_epoch=x_train.shape[0] / BATCH_SIZE,\n    epochs=15,\n    validation_data=(x_val, y_val) \n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr = []\nID=[]\ni=0\nfor image in os.listdir('../input/aptos2019-blindness-detection/test_images'):\n    id_ = image.split('.')[0]\n    scale = 300\n    img = preP('../input/aptos2019-blindness-detection/test_images/'+image)\n   \n    img = scaleRadius(img,scale)\n    h,w,_ = img.shape\n    img1=cv2.resize(crop_image(img[:,:,0]),(w,h))\n    img2=cv2.resize(crop_image(img[:,:,1]),(w,h))\n    img3=cv2.resize(crop_image(img[:,:,2]),(w,h))\n    img[:,:,0]=img1\n    img[:,:,1]=img2\n    img[:,:,2]=img3\n    imgr = cv2.resize(img,(224,224))\n    tr.append([id_,imgr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"T=[]\nID=[]\nfor id_,image in tr:\n    T.append(image)\n    ID.append(id_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"T=np.array(T).reshape(-1,224,224,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y1=model.predict(T) >0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nY1 = Y1.astype(int).sum(axis=1) - 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.concat([pd.DataFrame(ID),pd.DataFrame(Y1)],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.columns=['id_code','diagnosis']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}